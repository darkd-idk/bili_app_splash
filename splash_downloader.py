#!/usr/bin/env python3
"""
Bilibili Splash Image Downloader (Stable Version)

Version: 1.0.0
Updated: 2025-06-15
"""

import argparse
import hashlib
import json
import logging
import os
import time
from datetime import datetime
from pathlib import Path
import requests

# é…ç½®æ—¥å¿—
logger = logging.getLogger("BilibiliSplash")
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# API ç«¯ç‚¹é…ç½®
SPLASH_API = "https://api.bilibili.com/x/v2/splash/list"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    "Referer": "https://www.bilibili.com/",
}

class SplashDownloader:
    def __init__(self, output_dir="splash", url_file="splash_urls.txt", log_file="splash.log"):
        self.output_dir = Path(output_dir)
        self.url_file = Path(url_file)
        self.log_file = Path(log_file)
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.url_file.touch(exist_ok=True)
        self.log_file.touch(exist_ok=True)
        
        # è®¾ç½®æ–‡ä»¶æ—¥å¿—
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setFormatter(logging.Formatter('[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s'))
        logger.addHandler(file_handler)
        
        # åˆå§‹åŒ–è®¡æ•°å™¨
        self.downloaded_count = 0
        self.skipped_count = 0
        self.failed_count = 0
        self.start_time = time.time()
        
        # åŠ è½½URLåˆ—è¡¨
        self.url_set = self._load_url_set()
        
        logger.info("=" * 70)
        logger.info(f"ğŸ“ Output Directory: {self.output_dir}")
        logger.info(f"ğŸ”¤ URL File: {self.url_file}")
        logger.info(f"ğŸ“ Log File: {self.log_file}")
        logger.info("=" * 70)
    
    def _load_url_set(self):
        """åŠ è½½URLé›†åˆ"""
        url_set = set()
        try:
            if self.url_file.stat().st_size > 0:
                with open(self.url_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if '|' in line:
                            _, url = line.split('|', 1)
                            url_set.add(url.strip())
                        else:
                            url_set.add(line.strip())
                logger.info(f"Loaded {len(url_set)} URLs from URL list")
        except Exception as e:
            logger.error(f"Error loading URL set: {str(e)}")
        return url_set
    
    def _save_url(self, content_hash, url):
        """ä¿å­˜URLåˆ°æ–‡ä»¶"""
        try:
            with open(self.url_file, 'a', encoding='utf-8') as f:
                f.write(f"{content_hash}|{url}\n")
            self.url_set.add(url)
        except Exception as e:
            logger.error(f"Error saving URL: {str(e)}")
    
    def _fetch_splash_list(self):
        """è·å–å¼€å±å›¾åˆ—è¡¨"""
        try:
            logger.info(f"ğŸŒ Requesting splash list from API: {SPLASH_API}")
            
            # æ·»åŠ éšæœºå‚æ•°é¿å…ç¼“å­˜
            params = {
                "platform": "android",
                "device": "phone",
                "_": int(time.time() * 1000)  # æ—¶é—´æˆ³å‚æ•°é¿å…ç¼“å­˜
            }
            
            response = requests.get(
                SPLASH_API,
                headers=HEADERS,
                params=params,
                timeout=20
            )
            
            logger.info(f"ğŸ“¡ Received response: {response.status_code}")
            
            # æ£€æµ‹å“åº”çŠ¶æ€
            if response.status_code != 200:
                logger.error(f"API returned non-200 status: {response.status_code}")
                return None
                
            # ç¡®ä¿å“åº”ä¸ä¸ºç©º
            if not response.text.strip():
                logger.error("API returned empty response")
                return None
                
            # å°è¯•è§£æJSON
            try:
                data = response.json()
                
                # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„APIå“åº”
                if not isinstance(data, dict):
                    logger.error("API response is not a JSON object")
                    return None
                    
                # æ£€æŸ¥APIé”™è¯¯ä»£ç 
                if data.get('code') != 0:
                    error_msg = data.get('message', 'Unknown error')
                    logger.error(f"API error: {error_msg}")
                    return None
                    
                # è·å–å¼€å±å›¾åˆ—è¡¨
                splash_list = data.get('data', [])
                
                if not splash_list:
                    logger.warning("No splash images in API response")
                    return []
                    
                logger.info(f"ğŸ“š Found {len(splash_list)} splash items")
                return splash_list
                
            except json.JSONDecodeError as e:
                logger.error(f"JSON parsing failed: {str(e)}")
                logger.error(f"Response content: {response.text[:500]}...")
                return None
                
        except requests.RequestException as e:
            logger.error(f"Request failed: {str(e)}")
            return None
    
    def _download_image(self, url):
        """ä¸‹è½½å•ä¸ªå›¾ç‰‡"""
        if not url or len(url) < 10:
            return False
            
        # æ£€æŸ¥URLæ˜¯å¦å·²å¤„ç†
        if url in self.url_set:
            self.skipped_count += 1
            logger.info(f"â© URL already processed: {url}")
            return False
            
        try:
            logger.info(f"â¬‡ï¸ Downloading: {url}")
            
            # æ·»åŠ æ—¶é—´æˆ³é¿å…ç¼“å­˜
            url += ('&' if '?' in url else '?') + f"ts={int(time.time())}"
            
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            
            # è®¡ç®—å†…å®¹å“ˆå¸Œ
            content_hash = hashlib.sha256(response.content).hexdigest()
            
            # åˆ›å»ºæ–‡ä»¶å
            filename = f"{content_hash}.jpg"
            save_path = self.output_dir / filename
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜
            if save_path.exists():
                self.skipped_count += 1
                logger.info(f"â© Content already exists: {filename}")
                return True
                
            # ä¿å­˜æ–‡ä»¶
            with open(save_path, 'wb') as f:
                f.write(response.content)
            
            # è®°å½•URL
            self._save_url(content_hash, url)
            
            self.downloaded_count += 1
            file_size = len(response.content) // 1024
            logger.info(f"âœ… Saved: {filename} ({file_size} KB)")
            return True
        except Exception as e:
            self.failed_count += 1
            logger.error(f"âŒ Download failed: {str(e)}")
            return False
    
    def run(self):
        """æ‰§è¡Œä¸‹è½½æµç¨‹"""
        logger.info("ğŸš€ Starting splash image download")
        success = False
        
        try:
            splash_list = self._fetch_splash_list()
            
            if splash_list is None:
                logger.error("âŒ Failed to fetch splash list")
                return False
                
            # å¤„ç†æ¯ä¸ªå¼€å±å›¾
            for item in splash_list:
                try:
                    # è·å–å›¾ç‰‡URL
                    img_url = item.get('thumb') or item.get('image') or item.get('url')
                    if img_url:
                        self._download_image(img_url)
                except Exception as e:
                    logger.error(f"Error processing item: {str(e)}")
            
            success = True
        except Exception as e:
            logger.exception(f"Critical error: {str(e)}")
            success = False
            
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        elapsed = time.time() - self.start_time
        logger.info("=" * 60)
        logger.info(f"ğŸš€ Download Summary - {elapsed:.2f} seconds")
        logger.info(f"âœ… Downloaded: {self.downloaded_count}")
        logger.info(f"â© Skipped: {self.skipped_count}")
        logger.info(f"âŒ Failed: {self.failed_count}")
        logger.info(f"ğŸ Status: {'Success' if success else 'Failed'}")
        logger.info("=" * 60)
        
        return success

def main():
    parser = argparse.ArgumentParser(description="Bilibili Splash Image Downloader")
    parser.add_argument("--output", default="splash", help="Output directory for images")
    parser.add_argument("--url-file", default="splash_urls.txt", help="File to track downloaded URLs")
    parser.add_argument("--log-file", default="splash.log", help="Path to log file")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging")
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("ğŸ› Debug mode enabled")
    
    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
    downloader = SplashDownloader(
        output_dir=args.output,
        url_file=args.url_file,
        log_file=args.log_file
    )
    
    # æ‰§è¡Œä¸‹è½½
    success = downloader.run()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
